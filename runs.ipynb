{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import tarfile  \n",
    "import requests  \n",
    "import torchvision.transforms as transforms  \n",
    "import torchvision.datasets as datasets  \n",
    "from torch.utils.data import DataLoader  \n",
    "import torch.optim as optim  \n",
    "\n",
    "# Step 1: Download and extract the dataset  \n",
    "dataset_url = \"http://diode-dataset.s3.amazonaws.com/val.tar.gz\"  \n",
    "dataset_dir = './diode_dataset'  \n",
    "\n",
    "if not os.path.exists(dataset_dir):  \n",
    "    os.makedirs(dataset_dir)  \n",
    "\n",
    "# Download the dataset  \n",
    "response = requests.get(dataset_url)  \n",
    "with open(os.path.join(dataset_dir, 'val.tar.gz'), 'wb') as f:  \n",
    "    f.write(response.content)  \n",
    "\n",
    "# Extract the dataset  \n",
    "with tarfile.open(os.path.join(dataset_dir, 'val.tar.gz'), 'r:gz') as tar:  \n",
    "    tar.extractall(path=dataset_dir)  \n",
    "\n",
    "# Step 2: Set up the model and dataset  \n",
    "class ConvBlock(nn.Module):  \n",
    "    # ... (rest of ConvBlock class remains unchanged)  \n",
    "\n",
    "class RegNet(nn.Module):  \n",
    "    # ... (rest of RegNet class remains unchanged)  \n",
    "\n",
    "# Initialize model  \n",
    "num_classes = len(os.listdir(dataset_dir))  # Assuming each subdir is a class  \n",
    "model = RegNet(num_classes=num_classes)  \n",
    "\n",
    "# Step 3: Data loading and preprocessing  \n",
    "transform = transforms.Compose([  \n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "])  \n",
    "\n",
    "# Assuming the dataset has subdirectories for each class  \n",
    "dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)  \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)  \n",
    "\n",
    "# Step 4: Training setup  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "model.to(device)  \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# Step 5: Training loop  \n",
    "num_epochs = 10  # Adjust as necessary  \n",
    "for epoch in range(num_epochs):  \n",
    "    model.train()  \n",
    "    running_loss = 0.0  \n",
    "\n",
    "    for images, labels in dataloader:  \n",
    "        images, labels = images.to(device), labels.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()  # Zero gradients  \n",
    "        outputs = model(images)  # Forward pass  \n",
    "        loss = criterion(outputs, labels)  # Compute loss  \n",
    "        loss.backward()  # Backpropagation  \n",
    "        optimizer.step()  # Optimize  \n",
    "\n",
    "        running_loss += loss.item()  \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")  \n",
    "\n",
    "# Step 6: Save the model  \n",
    "torch.save(model.state_dict(), 'regnet.pth')  \n",
    "print(\"Model saved.\")  \n",
    "\n",
    "# Optional: Validate the model or visualize predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
